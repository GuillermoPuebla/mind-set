# options: 'classification', 'regression'
task_type = ""
gpu_num = 0

[network]
# Use either "resnet152_decoder" or "resnet_152_decoder_residual" for a deeper decoder with three pre-activation residual blocks, each containing two convolutional layers. . 
architecture_name = "resnet152_decoder" 
# Only used for regression method, and should be equal to the number of values the network should predict (generally this is 1). For classification, the number of outputs is set equal to the number of classes
decoder_outputs = 1
# Whether to use the ResNet152 version pretrained with ImageNet.
imagenet_pretrained = true
# If you want to load a state_dict of a pretrained ResNet152 with decoders, specify the path here. If you use this, "imagenet_pretraing" will be ignored. 
load_path = false
batch_size = 64


[training]
# If train_id == false, then run_id will be set equal to current date and time.
# Other key value pairs will be added in `run_info` by the train script.
train_id = false
learning_rate = 1e-5
weight_decay = 0
# If you want to continue training from a previous session, set this flag to the path of the optimizer (e.g. "models/decoder/id/checkpoint_optimizer.pt"). You also might want to change the network.load_model above. Note that if you haven't saved the optimizer state, you can still continue training with a loaded model (but it won't start training exactly from the same point as before). 
optimizers_path = false
save_trained_model = true
# If the following is false, a model and optimizer will be only saved at the end of the training session, not at every epoch
save_at_epoch_end = true  
# If True, it will evaluate the datasets specified as [[datasets.validation]] at some intervals during training
evaluate_during_training = false

# Note: for a classification task, we expect ALL datasets (training and validation) to have the same number of classes.
[training.dataset]
name = "training"
annotation_file = "path/to/annotation/file.csv"
img_path_col_name = "Path"
# Use either a string or a list of string for a regression task. For a classification task, only a single string is permitted (either in a list or not)
label_cols = ["ImageNetClassIdx"]
# filters = { Type = "random" }

# Example of validation datasets.

# [[eval.datasets]]
# name = "name_val1"
# annotation_file = ""
# img_path_col_name = "Path"
# label_cols = ["val1"]
# filters = { Type = "blabla"}

# You can use more than one validation dataset
# [[eval.datasets]]
# name = "name_val2"
# annotation_file = ""
# img_path_col_name = "Path"
# label_cols = ["val2"]
# filters = { Type = "blabla"}


[training.stopping_conditions]
# TODO: Explain this!
stop_at_epoch = 50
stop_at_loss = false
stop_at_accuracy = false

[training.monitoring]
# If you want to log in neptune.ai, specify the project name. You need an account there + you need to have created a project with the correct name through their UI + You need to set up your API token: \nhttps://docs.neptune.ai/getting-started/installation. The API should be in an environmental variable called NEPTUNE_API_TOKEN.
# If everything is setup correctly, put your project name here, and you should get a lot of good logging for your training session'
neptune_proj_name = false


[saving_folders]
# The paths for saving the results and the model. If false, no saving will occur. Notice that, during training, the `train_id` will be appended to these folders. 
results_folder = 'results/classification/'
model_output_folder = 'models/classification/'

[transformation]
fill_color = [0, 0, 0]

[transformation.values]
# TODO: Fix Documentation. 
# Set it to "false" to not apply the respective transformation. 
translation = [-0.2, 0.2] 
scale = [0.7, 1.3]
rotation = [0, 360]