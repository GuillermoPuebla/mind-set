[basic_info]
# The path of the annotation file. The annotation files are generally at the top level of a dataset directory. Here a "column" in the annotation file is referred to as a "Factor" and the values this factors can take are "Levels". 
annotation_file_path = ""
# Specify which factor you are gonna compare across. Every image of every level of this factor is gonna be compared against every image in the reference_level level. For example, the annotation contains  the factor "ObjectSize" with levels "Large", "Small", "Medium". If we set factor_variable = "ObjectSize" and reference_level = "Medium", then each image of ObjectSize == Large and ObjectSize == Small will be compared with each other image of ObjectSize == "Medium".
factor_variable = ""
reference_level = ""

# The comparison outlined above, utilizing the two configuration variables, can be further refined through the config parameter  `match_factors`. Suppose we aim to compare images where `ObjectSize`= "Medium" against "Large" and "Small" images. But image we have another factor, call "Shape" (e.g. with levels "Square" and "Triangle"). We wish to make the size comparisons on the condition that objects share the same "Shape" level.
# That is, we want to make sure to compare LargeObject_Circle.png with MediumObject_Circle.png, and LargeObject_Square.png with MediumObject_Square.png. To do that, specify the factors that needs to match across comparison. E.g. match_factors = ["Shape"]. You can specify multiple match_factors.
match_factors = ""

# Put here any filter you want to apply to the annotation file. For example, if you only want to consider those images for which the "Type" column is equal to "random" and the "ObjectNum" is equal to 23, write
# [filter_factor_level]
# Type = "random"
# ObjectNum = 23
filter_factor_level = {}


[options]
# Either [euclidean] or [cossim] (cosine similarity)
distance_metric = "euclidean"
#  Supported networks: `alexnet`, `vgg11`, `vgg16`, `vgg11bn`, `vgg16bn`, `vgg19bn`, `resnet18`, `resnet50`, `resnet152`, `inception_v3` , `densenet121`, `densenet201`, `googlenet`. 
network_name = "resnet152"
# Specify against what layer we want to etract the network activation. A layer will be used if its module name contains any of the string in this list. For example, you could add "MaxP", "Relu" for saving the results of the corresponding modules. 
save_layers = ["Conv2d", "Linear"]
# If you have multiple GPUs, specify what GPU to use.
gpu_num = 0
# Whether to use the version of the network pretrained on ImageNet or not. Use "vanilla" to use a network without any pretraining. 
pretraining = "ImageNet"

[saving_folders]
# Where to save the results of the analysis. 
results_folder = "results/similarity_judgment/tmp"
# Whether we want to create a folder inside the results_folder containing debugging images.
save_debug_images = true

[transformation]

# Specify what transformation to apply.. Use t/s/r for translation, scale and rotation, and square brackets with the transformation limits. A uniform random value will be drown within the specified limits. E.g. "t[-0.2, 0.2]r[-50, 50]" will apply translation from -0.2 to 0.2 (normalized to image size), and rotation from -50 to +50 degrees. If you don't specify any limit values in the square brackets, default values will be used. For example "t[-0.2, 0.2]sr" will use the default values for scale and rotation, and the specified values for translation.  Default values are t=[-0.2, 0.2], s=[0.7, 1.3], r=[0, 360]. Leave empty "" for no transformation. 
# affine_transf_code = "t[-0.2, 0.2]r[-50, 50]"

# When rotating/scaling the image, a "fill in" background will be used. Specify it here with a tuple of ints from 0 to 255. Default is black: (0, 0, 0). 
fill_color = [0, 0, 0]
# We always compare "pairs" of images. With this parameter, specify whether the _same_ transformation  should be applied to both images of a comparion pair (e.g. rotate and translate both images by exactly the same amount). If affine_transf_code == "", this will be ignored.
matching_transform = true
# How many times do we need to repeat a transformed sample. Only applies when you use some type of transformation: if affine_transf_code == "", this will be set to 1
repetitions = 50

# Whether we want to copy the images found in the folders onto a bigger canvas. The canvas background will be `fill_color`. The canvas will be `canvas_to_image_ratio` along the horizontal dimension, and it will be a square. For example, if the image is 100x50 pixels, it will be pasted onto a canvas large 300x300 pixels. 
copy_on_bigger_canvas = false
canvas_to_image_ratio = 3

[transformation.values]
# TODO: Fix Documentation. 
# Set it to "false" to not apply the respective transformation. 
translation = [-0.2, 0.2] 
scale = [0.7, 1.3]
rotation = [0, 360]